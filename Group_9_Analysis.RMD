---
title: "Group_9_Analysis"
author: "Brent Strong, Enyu Li, Haotian Wang, Honjin Ren, Mu He"
date: "3/7/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, message = FALSE, warning = FALSE)
```

Note that some comments appear as both comments in the code (denoted by the symbol #) and text to be included in the knitted pdf file. This is done so that regardless of whether one is looking at the RMarkdown file or the knitted pdf file it is clear what the purpose of a block of code or table/chart is.

```{r libraries, echo = FALSE}

#Load necessary libraries for the data exploration and analysis

library(tidyverse)
library(moderndive)
library(skimr)
library(kableExtra)
library(gridExtra)
library(broom)
library(olsrr)
library(gapminder)
library(sjPlot)
library(stats)
library(jtools)
library(MASS)
library(janitor)
library(ggplot2)
library(caret)
library(lme4)
library(ROCR)
library(vcdExtra)
```

```{r import, echo = FALSE}

#Read in data from github and abbreviate certain country names in order to improve the appearance of the plots.

analysis <- read_csv("https://raw.githubusercontent.com/brent-strong/DAS2022-Group-09/main/dataset9.csv")

for(i in 1:nrow(analysis)){
  if(str_detect(analysis$country_of_origin[i], "Puerto Rico")){
    analysis$country_of_origin[i] <- "Puerto Rico"
  }
  if(str_detect(analysis$country_of_origin[i], "Hawaii")){
    analysis$country_of_origin[i] <- "Hawaii"
  }
  if(str_detect(analysis$country_of_origin[i], "Tanzania")){
    analysis$country_of_origin[i] <- "Tanzania"
  }
  else{
    analysis$country_of_origin[i] <- analysis$country_of_origin[i]
  }
}

```

# Exploratory Data Analysis

Have a look at the summary statistics of the raw data.

```{r, echo=FALSE, eval = TRUE}

#Create table of summary statistics for each of the continuous variables. 

my_skim2 <- skim_with(numeric = sfl(hist = NULL))
analysis %>%
  dplyr::select(-country_of_origin, -Qualityclass) %>%
  my_skim2() %>%
  dplyr::select(-c(n_missing, complete_rate, skim_type)) %>%
  kable(col.names = c("Variable", "Mean", "SD", "Min.", "1st Q.", "Median",
                        "3rd Q.", "Max."), 
        caption = 'Summary statistics of continuous variables in the data set.',
        booktabs = TRUE, format = "latex", digits = 2) %>%
  kable_styling(font_size = 9, latex_options = "HOLD_position")
```

The following table shows the number of batches and the proportion of good quality for each country.

```{r}

#Create table to show the number of batches and the proportion of batches that are of good quality for each country.

my_skim <- skim_with(base = sfl(n = length))
my.analysis <- analysis %>%
  mutate(Qualityclassindicator = as.numeric(Qualityclass=="Good"))
my.analysis %>%
  group_by(country_of_origin) %>%
  dplyr::select(country_of_origin, Qualityclassindicator) %>%
  my_skim() %>%
  dplyr::select(country_of_origin, n, numeric.mean) %>%
  transmute(country_of_origin=country_of_origin,
            number_of_batch=n,
            Proportion_of_good_quality=numeric.mean) %>%
  kable(caption = '\\label{tab:countryskim} Number of batches and proportion of batches that are of good quality for each country', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

The following boxplot is for good quality rates for each country, in which we can check if any countries have unusual high or low good quality rate. It seems like all good quality rates lie in the IQR.

```{r , echo=FALSE, fig.width = 6, fig.align = "center", fig.cap = "Boxplots of good quality rate for each country.", fig.pos = 'H', message = FALSE}

#Create box plot of the proportion of batches that are good for each country.

analysis.country <- analysis %>%
  mutate(Qualityclassindicator = as.numeric(Qualityclass=="Good")) %>%
  group_by(country_of_origin) %>%
  dplyr::summarise(good_quality_porprotion = round(mean(Qualityclassindicator), 2),
            number_of_batch = n())

ggplot(data = analysis.country, mapping = aes(y = good_quality_porprotion)) +
  geom_boxplot()



```

The following table filter countries and its number of batch with 20% good quality rate before and after, which provides more detailed information than the above boxplot. The number of batch can imply the reliability. For instance, Colombia has a relatively high good quality rate with large number of batch. 

```{r, eval = TRUE}

#The following table filter countries and its number of batch with 20% good quality rate before and after, which provides more detailed information than the above boxplot. The number of batch can imply the reliability. For instance, Colombia has a relatively high good quality rate with large number of batch. 

analysis.country %>%
  filter(good_quality_porprotion <= quantile(good_quality_porprotion, probs = c(0.2, 0.8))[1] |
          good_quality_porprotion >= quantile(good_quality_porprotion, probs = c(0.2, 0.8))[2] ) %>%
  arrange(good_quality_porprotion) %>%
  kable(caption = '\\label{tab:countryodd} Origins with twenty percent good quality rate before and after', booktabs = TRUE,
        linesep ="",format = "latex", digits = 2) %>%
  kable_styling(font_size = 8, latex_options = "HOLD_position")

```

```{r , echo=FALSE, fig.width = 13, fig.align = "center", fig.cap = "Boxplots2 of countinous features on different quality class.", fig.pos = 'H', message = FALSE}

#Plot the distribution of each variable separately for coffee termed good and poor quality. Box plots are used. 

p1 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = aroma)) +
  geom_boxplot() +
  labs(x = 'Quality Class')
p2 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = flavor)) +
  geom_boxplot() +
  labs(x = 'Quality Class')
p3 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = acidity)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p4 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = category_two_defects)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p5 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = altitude_mean_meters)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p6 <- ggplot(data = analysis, mapping = aes(x = factor(Qualityclass), y = harvested)) +
  geom_boxplot()+
  labs(x = 'Quality Class')

grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 6)

```

There are several observations with extremely high altitudes which are impossible. Hence, delete observations which have an altitude higher than Mt. Everest.

```{r altitude2, echo = FALSE}

# Mt. Everest is only 8,849 meters tall. Remove any observations with altitudes higher than that.

analysis2 <- analysis %>%
  filter(altitude_mean_meters < 8849)
```

``` {r altitude3, echo=FALSE, fig.width = 13, fig.align = "center", fig.cap = "Histogram and boxplot for altitude after removing implausuble observations.", fig.pos = 'H', message = FALSE}

# Generate histogram to visualize altitude data after removing implausible observations.

p1 <- ggplot(data = analysis2, mapping = aes(x = altitude_mean_meters)) +
  geom_histogram()

# Generate boxplot to visualize altitude data after removing implausible observations.

p2 <- ggplot(data = analysis2, mapping = aes(y = altitude_mean_meters)) +
  geom_boxplot()

grid.arrange(p1, p2, ncol = 2)
```

The following two histograms compare the distributions of altitude before and after removing implausible observations.

``` {r altitude4, echo=FALSE, fig.width = 13, fig.align = "center", fig.cap = "Histogram for altitude befor and after removing implausuble observations.", fig.pos = 'H', message = FALSE}

# Generate histogram to visualize altitude data after removing implausible observations.

p1 <- ggplot(data = analysis, mapping = aes(x = altitude_mean_meters)) +
  geom_histogram(color = 'white')

# Generate boxplot to visualize altitude data after removing implausible observations.

p2 <- ggplot(data = analysis2, mapping = aes(x = altitude_mean_meters)) +
  geom_histogram(color = 'white')

grid.arrange(p1, p2, ncol = 2)
```

The following table compares the distribution of features between good and poor coffee. We can check if there are obvious differences in some features between good and poor coffee after data cleaning.

```{r, eval = TRUE}

#Create table showing numerical summaries for aroma, flavor, acidity, and category_two_defects separately for batches rates as good and poor for their quality.

analysis2 %>%
  group_by(Qualityclass) %>%
  dplyr::select(Qualityclass, aroma, flavor, acidity, category_two_defects, altitude_mean_meters, harvested) %>%
  my_skim() %>%
  transmute(Variable=skim_variable, Qualityclass=Qualityclass, n=n, Mean=numeric.mean, SD=numeric.sd,
            Min=numeric.p0, Median=numeric.p50,  Max=numeric.p100,
            IQR = numeric.p75-numeric.p50) %>%
  kable(caption = '\\label{tab:catskim} Summary statistics of features of good and poor coffee', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

```{r boxplots, echo = FALSE}

# glimpse(analysis)

# Remove observations that have implausible values for at least one of the variables including the observation with a  score of 0 for aroma, acidity, and flavor. Turn Qualityclass into an indicator variable so that it can be used in the logistic regression analysis. Remove unneeded variables.

coffee_final <- analysis %>%
  na.omit() %>%
  filter(altitude_mean_meters < 8849) %>%
  mutate(year = as.factor(harvested), Qualityclass = 0 + as.numeric(Qualityclass == "Good")) 

#Create a 3 level categorical variable for the altitude based on review of the literature @hameed_coffee_2020

coffee_final$level_1 <- ifelse(coffee_final$altitude_mean_meters<900,1,0)
coffee_final$level_2 <- ifelse(coffee_final$altitude_mean_meters>=900 & coffee_final$altitude_mean_meters<=1200,1,0)
coffee_final$level_3 <- ifelse(coffee_final$altitude_mean_meters>1200,1,0)
coffee_final <- coffee_final %>%
  mutate(level = as.character(level_1 + level_2*2 + level_3*3))

# Finally, create the final data set by removing any unnecessary variables. 

coffee_final <- coffee_final %>%
  dplyr::select(country_of_origin, aroma, flavor, acidity, category_two_defects, year, level, Qualityclass)

# View the final data set and make sure that the standardizations and transformation were appropriately applied.

# glimpse(coffee_final)

# skim_without_charts(coffee_final)
```


Here is 6 box-plots comparing features distribution between good and poor coffee after data cleaning.

```{r , echo=FALSE, fig.width = 13, fig.align = "center", fig.cap = "Boxplots of countinous features on different quality class after data cleaning.", fig.pos = 'H', message = FALSE}

#Remove any observations with missing values.

coffee_final2 <- analysis %>%
  na.omit() %>%
  filter(altitude_mean_meters < 8849)

#Create box plots that show the distribution of each of the variables by quality class after removing missing values. 

p1 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = aroma)) +
  geom_boxplot() +
  labs(x = 'Quality Class')
p2 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = flavor)) +
  geom_boxplot() +
  labs(x = 'Quality Class')
p3 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = acidity)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p4 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = category_two_defects)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p5 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = altitude_mean_meters)) +
  geom_boxplot()+
  labs(x = 'Quality Class')
p6 <- ggplot(data = coffee_final2, mapping = aes(x = factor(Qualityclass), y = harvested)) +
  geom_boxplot()+
  labs(x = 'Quality Class')

grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 6)

```

```{r , echo=FALSE, fig.width = 8, fig.align = "center", fig.cap = "The good and poor quality rates for each altitude level.", fig.pos = 'H', message = FALSE}

#Create a data set with all observations that have missing values removed. 

coffee_final2 <- analysis %>%
  na.omit() %>%
  filter(altitude_mean_meters < 8849) %>%
  mutate(year = as.factor(harvested))

#Create the same 3 level categorical variable for altitude based on the review of the literature.

coffee_final2$level_1 <- ifelse(coffee_final2$altitude_mean_meters<900,1,0)
coffee_final2$level_2 <- ifelse(coffee_final2$altitude_mean_meters>=900 & coffee_final2$altitude_mean_meters<=1200,1,0)
coffee_final2$level_3 <- ifelse(coffee_final2$altitude_mean_meters>1200,1,0)
coffee_final2 <- coffee_final2 %>%
  mutate(level = as.character(level_1 + level_2*2 + level_3*3))

#Create a bar char to visualize the proportion of good and poor batches by altitude level. 

ggplot(coffee_final2, aes(x= level,  y = ..prop.., group = as.factor(Qualityclass), fill = Qualityclass)) + 
    geom_bar(position="dodge", stat="count") +
    labs(y = "Proportion")

```

# Formal Analysis Using Logistic Regression

Firstly we fit a model using altitude levels as the only explanatory variable.
```{r}

#Fit model with no intercept and only altitude as a predictor to get an idea of how quality differs by altitude level.

model_level <- glm(Qualityclass ~ level - 1, data = coffee_final,family = binomial(link = "logit"))
summary(model_level)
```

```{r}

#Create a summary table from the logistic regression with just altitude level as a predictor. 

modelsumm <- summary(model_level)
CI <- confint(model_level)
citable <- data.frame(modelsumm$coefficients) %>%
  round(2)
colnames(citable)[1] <- "Estimate" 
colnames(citable)[2] <- "Std error"
colnames(citable)[3] <- "Statistics"
colnames(citable)[4] <- "P_value"
citable$Lower_ci <- CI[,1]
citable$Upper_ci <- CI[,2]
citable <- citable[,-3]
knitr::kable(citable, caption = 'confidence interval of estimated parameters', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

If the level of altitude is the only explanatory variable in the model, the effect of three levels are all statistically significant. In detail, high altitude has a positive influence on the quality of coffee.

Secondly, we fit a model using harvested year as the only explanatory variable.

```{r}

#Fit model with only year as a predictor to get an idea of how quality differs by year of harvest.

model_year <- glm(Qualityclass ~ year - 1, data = coffee_final,family = binomial(link = "logit"))
summary(model_year)

coffee_final$year2010 <- ifelse(coffee_final$year == 2010,1,0)
coffee_final$year2011 <- ifelse(coffee_final$year == 2011,1,0)
coffee_final$year2012 <- ifelse(coffee_final$year == 2012,1,0)
```

```{r}

#Create a summary table from the logistic regression with just year of harvest as a predictor. 

modelsumm <- summary(model_year)
CI <- confint(model_year)
citable <- data.frame(modelsumm$coefficients) %>%
  round(2)
colnames(citable)[1] <- "Estimate" 
colnames(citable)[2] <- "Std error"
colnames(citable)[3] <- "Statistics"
colnames(citable)[4] <- "P_value"
citable$Lower_ci <- CI[,1]
citable$Upper_ci <- CI[,2]
citable <- citable[,-3]
citable <- citable %>%
  filter(P_value < 0.05)
knitr::kable(citable, caption = 'confidence interval of estimated parameters', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

If harvested year is the only explanatory variable in the model, the effects of year 2010, 2011 and 2012 are statistically significant. Coffee harvested in year 2012 has a higher odds ratio. Coffee harvested in year 2010 and 2011 has a lower odds ratio.

Then, we fit a model using country of region as the only explanatory variable.
```{r}

#Fit model with only country as a predictor to get an idea of how quality differs by country of harvest.

model_country <- glm(Qualityclass ~ country_of_origin - 1, data = coffee_final,family = binomial(link = "logit"))
summary(model_country)
```

```{r}

#Create a summary table from the logistic regression with just country as a predictor.

modelsumm <- summary(model_country)
CI <- confint(model_country)
citable <- data.frame(modelsumm$coefficients) %>%
  round(2)
colnames(citable)[1] <- "Estimate" 
colnames(citable)[2] <- "Std error"
colnames(citable)[3] <- "Statistics"
colnames(citable)[4] <- "P_value"
citable$Lower_ci <- CI[,1]
citable$Upper_ci <- CI[,2]
citable <- citable[,-3]
citable <- citable %>%
  filter(P_value < 0.05)
knitr::kable(citable, caption = 'confidence interval of estimated parameters', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

If the country of origin is the only explanatory variable, Colombia, Mexico, Honduras, Kenya, Malawi, Uganda have statistically significant effect on the odds ratio.

```{r}

#Create indicator variables for countries that appear to have a significant influence on the quality of a harvest. These will be used to simplify the model in later iterations. 

coffee_final$Colombia <- ifelse(coffee_final$country_of_origin == 'Colombia',1,0)
coffee_final$Mexico <- ifelse(coffee_final$country_of_origin == 'Mexico',1,0)
coffee_final$Honduras <- ifelse(coffee_final$country_of_origin == 'Honduras',1,0)
coffee_final$Kenya <- ifelse(coffee_final$country_of_origin == 'Kenya',1,0)
coffee_final$Malawi <- ifelse(coffee_final$country_of_origin == 'Malawi',1,0)
coffee_final$Uganda <- ifelse(coffee_final$country_of_origin == 'Uganda',1,0)
```

All variables which are significant above are considered to be potential explanatory variables. They are all three altitude levels, year 2010, 2011 and 2012 and countries of Colombia, Mexico, Honduras, Kenya, Malawi and Uganda.

The following model use all potential  explanatory variables. And use step AIC to select variables again.
```{r, warning=FALSE}

#Generate a model with all significant variables from above and the other predictors (aroma, flavor, acidity, and category_two_defects).

model_all_significant <- glm(Qualityclass ~ aroma + flavor + acidity + Colombia + Mexico + Honduras + Kenya + Malawi + Uganda + category_two_defects + level + year2010 + year2011 + year2012, data = coffee_final,family = binomial(link = "logit"))

summary(model_all_significant)

#Find the model that best fits the data using AIC. Incomplete observations are dropped.

model_slected <- stepAIC(model_all_significant, direction = 'both')
summary(model_slected)
```

In the selected model, two terms are not significant. Then, we try to delete term Uganda which has the highest p-value.

After deleting Uganda, category_two_defects is still not significant. Hence, it was deleted.
And we use anova to compare three models.
There isn't a statistically significant difference among them.
Hence, it is reasonable to delete them and get a simple model.

```{r}

#Fit a logistic regression model without Uganda as a predictor since it wasn't significant. 

model2 <- glm(Qualityclass ~ aroma + flavor + acidity + Colombia + Mexico + category_two_defects, data = coffee_final,family = binomial(link = "logit"))

#Fit a logistic regression model without category_two_defects since it wasn't significant after dropping Uganda.

model3 <- glm(Qualityclass ~ aroma + flavor + acidity + Colombia + Mexico, data = coffee_final,family = binomial(link = "logit"))

#The warning occurs because of one observation that has a value of 0 for aroma, flavor, and acidity. Note that removing this observation has virtually no impact on the model fit. 

#Compare the quality of the fit of the different models. 

summary(model2)
summary(model3)
anova(model_slected, model2, model3)
qchisq(df = 1, p = 0.95)
```

## Final Model
```{r}

#Show summary statistics for the final model. 

summary(model3)
```

Create regression equations for use in the presentation.

$$ Qualityclass \sim Harvested_{\mbox{year}} - 1$$

$$ Qualityclass \sim Altitude_{\mbox{level}} - 1 $$

$$ Qualityclass \sim Origin_{\mbox{country}} - 1 $$


$$\ln(\frac{p_i}{1-p_i}) = \alpha + \beta_1 \cdot aroma_i+ \beta_2 \cdot flavor_i+ \beta_3 \cdot acidity_i+ \beta_4 \cdot \mathbb{I}_{\mbox{Colombia}}(x)+ \beta_5 \cdot \mathbb{I}_{\mbox{Mexico}}(x)$$

$$\mathbb{I}_{\mbox{Colombia}}(x)=\left\{ \begin{array}{ll} 1 ~~~ \mbox{if Country of region of} ~ x \mbox{th observation is Colombia},\\ 0 ~~~ \mbox{Otherwise}.\\ \end{array} \right. $$

$$\mathbb{I}_{\mbox{Mexico}}(x)=\left\{ \begin{array}{ll} 1 ~~~ \mbox{if Country of region of} ~ x \mbox{th observation is Mexico},\\ 0 ~~~ \mbox{Otherwise}.\\ \end{array} \right.$$
The following is the fitted model.

$$\ln(\frac{p_i}{1-p_i}) = `r round(coef(model3), 2)[1]` + `r round(coef(model3), 2)[2]` \cdot aroma_i+ `r round(coef(model3), 2)[3]` \cdot flavor_i+ `r round(coef(model3), 2)[4]` \cdot acidity_i+ `r round(coef(model3), 2)[5]` \cdot \mathbb{I}_{\mbox{Colombia}}(x) `r round(coef(model3), 2)[6]` \cdot \mathbb{I}_{\mbox{Mexico}}(x)$$

Generate a summary table containing confidence intervals of estimated parameters of final model.

```{r}

#Create table with confidence intervals for each of the estimates from the final model.

modelsumm <- summary(model3)
CI <- confint(model3)
citable <- data.frame(modelsumm$coefficients) %>%
  round(2)
colnames(citable)[1] <- "Estimate" 
colnames(citable)[2] <- "Std error"
colnames(citable)[3] <- "statistic"
colnames(citable)[4] <- "P value"
citable$Lower_ci <- CI[,1]
citable$Upper_ci <- CI[,2]
citable <- citable[,-3]
knitr::kable(citable, caption = '\\label{tab:ci} confidence interval of estimated parameters', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```
```{r}

#Create table with confidence intervals for each of the estimates from the final model.
citable$Lower_ci <- CI[,1]
citable$Upper_ci <- CI[,2]
citable$Exp_lower_ci <- exp(citable$Lower_ci)
citable$Exp_upper_ci <- exp(citable$Upper_ci)

knitr::kable(citable[,6:7], caption = '\\label{tab:ci} confidence interval of odds', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```


Based on the model we built, we try to use 10-fold cross validation to test the validity of our final model. In the validation we assess three criteria: accuracy, sensitivity and specificity.

```{r, warning=FALSE}

#Perform 10-fold cross validation to assess the predictive performance of the model. Calculate overall accuracy, sensitivity, and specificity. 

set.seed(9)
folds <- createFolds(y=coffee_final$Qualityclass, k=10)
accuracy <- as.numeric()
sensitivity <- as.numeric()
specificity <- as.numeric()
for(i in 1:10){
  fold_test <- coffee_final[folds[[i]],]
  fold_train <- coffee_final[-folds[[i]],]
  fold_pre <- glm(Qualityclass ~ aroma + flavor + acidity + Colombia + Mexico,family = binomial(link = logit), data =fold_train )
  fold_predict <- predict(fold_pre,type='response',newdata=fold_test)
  fold_predict <- ifelse(fold_predict >= 0.5, 1, 0)
  accuracy[i] <- mean(fold_predict == fold_test[,8])
  sensitivity[i] <- sum(fold_predict + fold_test[,8] == 2) / sum(fold_test[,8] == 1)
  specificity[i] <- sum(fold_predict + fold_test[,8] == 0) / sum(fold_test[,8] == 0)
}
mean(accuracy)

mean(sensitivity)

mean(specificity)
```
The accuracy of our final model is `r round(mean(accuracy), 2)`.
The sensitivity of our final model is `r round(mean(sensitivity), 2)`.
The specificity of our final model is `r round(mean(specificity), 2)`.

```{r}
HLtest(model3, g=10)
```
However, the model has good predicting performance, it failed in Hosmer-Lemeshow Goodness of Fit Test.

## Classfication boundry

```{r}

#Evaluate the performance of the final model graphically. Generate a receiver operating characteristic curve.

coffee_final$prid <- predict(model3, coffee_final, type='response')
score <- prediction(coffee_final$prid, coffee_final$Qualityclass)
perf <- performance(score, 'tpr', 'fpr')
auc <- performance(score, 'auc')
perfd <- data.frame(x=perf@x.values[1][[1]], y=perf@y.values[1][[1]])
ggplot(perfd, aes(x= x, y=y)) + geom_line() +
  xlab("False positive rate") + ylab("True positive rate") +
  ggtitle(paste("Area under the curve:", round(auc@y.values[[1]], 3))) + 
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = 'red')

```

```{r}

#Create a table with the regression coefficients before and after exponentiation. 

round(coef(model3),2)
round(exp(coef(model3)),2)
co <- rbind(round(coef(model3),2),round(exp(coef(model3)),2))
row.names(co) <- c("coefficients","exp(coefficients)")

co %>%
  knitr::kable(caption = '\\label{tab:summaries} Regression coefficients and exponentiated coefficients.', booktabs = TRUE, linesep = "", digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "HOLD_position")

```

```{r}

#Create a plot showing odds ratios (exponentiated regression coefficients) for each predictor variable.

plot_model(model3, show.values = TRUE,
           title = "Odds", show.p = FALSE)
```


```{r}
# Create a function which can find the best cutoff point automatically to use for classification

findbestcut <- function(model, data){
  data$prid <- predict(model, data, type='response')
  score <- prediction(data$prid, data$Qualityclass)
  perf <- performance(score, 'tpr', 'fpr')
  cutoffs <- data.frame(cut=perf@alpha.values[[1]], dif=perf@y.values[[1]] - perf@x.values[[1]])
  bestcut <- cutoffs[order(cutoffs$dif, decreasing = T), ]$cut[1]
  return(bestcut)
}

```

```{r, warning=FALSE}

#Perform 10-fold cross validation to assess the predictive performance of the model which can use best cutoff point automatically.
#Calculate overall accuracy, sensitivity, and specificity. 

set.seed(9)
folds <- createFolds(y=coffee_final$Qualityclass, k=10)
accuracy <- as.numeric()
sensitivity <- as.numeric()
specificity <- as.numeric()
for(i in 1:10){
  fold_test <- coffee_final[folds[[i]],]
  fold_train <- coffee_final[-folds[[i]],]
  fold_pre <- glm(Qualityclass ~ aroma + flavor + acidity + Colombia + Mexico,family = binomial(link = logit), data =fold_train )
  fold_predict <- predict(fold_pre,type='response',newdata=fold_test)
  fold_predict <- ifelse(fold_predict >= findbestcut(fold_pre, fold_train), 1, 0)
  accuracy[i] <- mean(fold_predict == fold_test[,8])
  sensitivity[i] <- sum(fold_predict + fold_test[,8] == 2) / sum(fold_test[,8] == 1)
  specificity[i] <- sum(fold_predict + fold_test[,8] == 0) / sum(fold_test[,8] == 0)
}
mean(accuracy)

mean(sensitivity)

mean(specificity)

# The accuracy and sensitivity are improved a little bit.
```
After adjusting the classification boundary.
The accuracy of our final model is `r round(mean(accuracy), 2)`.
The sensitivity of our final model is `r round(mean(sensitivity), 2)`.
The specificity of our final model is `r round(mean(specificity), 2)`.

## Sensitivity analysis

In addition, we try the linear mixed model. However, it doesn't improve the performance of predicting.

```{r, eval=T}

#Fit a linear mixed model with a random intercept for country. Included all other predictors from the final, best model.

glmm1 <- glmer(Qualityclass ~ 1 + aroma + flavor + acidity + (1|country_of_origin),
               data=coffee_final, family=binomial(link="logit"))
summary(glmm1, corr=FALSE)
```

```{r, warning=FALSE}

#Perform 10-fold cross validation to assess the predictive performance of the mixed model (i.e. model with just aroma, flavor, and acidity as terms). Calculate overall accuracy, sensitivity, and specificity. 

set.seed(9)
folds <- createFolds(y=coffee_final$Qualityclass, k=10)
accuracy <- as.numeric()
sensitivity <- as.numeric()
specificity <- as.numeric()
for(i in 1:10){
  fold_test <- coffee_final[folds[[i]],]
  fold_train <- coffee_final[-folds[[i]],]
  fold_pre <- glm(Qualityclass ~ aroma + flavor + acidity, family = binomial(link = logit), data =fold_train )
  fold_predict <- predict(fold_pre,type='response',newdata=fold_test)
  fold_predict <- ifelse(fold_predict >= 0.5, 1, 0)
  accuracy[i] <- mean(fold_predict == fold_test[,8])
  sensitivity[i] <- sum(fold_predict + fold_test[,8] == 2) / sum(fold_test[,8] == 1)
  specificity[i] <- sum(fold_predict + fold_test[,8] == 0) / sum(fold_test[,8] == 0)
}
mean(accuracy)

mean(sensitivity)

mean(specificity)
```
If only use aroma, flavour and acidity grades as explantatory variables.
The accuracy of the model is `r round(mean(accuracy), 2)`.
The sensitivity of the model is `r round(mean(sensitivity), 2)`.
The specificity of the model is `r round(mean(specificity), 2)`.